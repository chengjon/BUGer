# Web端程序BUG修复AI协作规范（纲领版 v4.0）

> **核心理念**: 从"相信AI已修复"转变为"我用证据验证AI修复成功"

---

## 📋 目录

- [一、核心协作原则](#一核心协作原则)
- [二、BUG修复任务规范](#二bug修复任务规范)
- [三、工具使用指导方针](#三工具使用指导方针)
- [四、AI修复输出标准](#四ai修复输出标准)
- [五、验证与闭环机制](#五验证与闭环机制)
- [六、效率与成本控制](#六效率与成本控制)
- [七、禁止性规定](#七禁止性规定)
- [八、质量保障体系](#八质量保障体系)

---

## 一、核心协作原则

### 1.1 精准需求原则

#### 禁止模糊表述
**不建议的提需方式**:
- ❌ "修复登录的BUG"
- ❌ "解决所有问题"
- ❌ "让这个功能能用"

**必须遵守的提需格式**:
- ✅ **现象**: 具体的错误表现（如"点击登录按钮无反应，控制台报错XXX"）
- ✅ **预期**: 明确的成功标准（如"登录后跳转到/dashboard页面"）
- ✅ **验证标准**: 可量化的检验方式（如"localStorage中存在token且控制台无错误"）

#### 优先级强制分级
- **P0 - 阻断性**: 影响核心业务流程，必须立即修复
- **P1 - 重要**: 影响用户体验，应尽快修复
- **P2 - 一般**: 次要问题，可安排修复

**执行要求**: 
- 单次仅处理 **2-3个问题**
- 多个问题，请分次处理
- 严格按优先级顺序处理
- P0未解决前，不得开始P1
- 对于问题描述不清晰，AI可以重新描述问题，请用户确认后再修复
- 同一问题连续3次修复失败，需升级处理（人工介入或更换方案）

### 1.2 小步迭代原则

#### 单次修改范围限制
- **允许**: 修改1-2个相关函数/文件
- **禁止**: 一次性修改多个无关模块
- **禁止**: "顺便优化"其他无关代码
- **禁止**: "顺带重构"无关代码

#### 最小变更原则
- 只修改"目标相关"的最小代码块
- 修复函数bug时，不触碰其他无关函数
- 新增功能优先用"扩展"而非"修改"
- 发现其他问题时，单独创建BUG记录，不在本次修复中处理

#### 扩展优先策略示例
```
# ❌ 错误方式：直接修改原有函数
def crawl_data():
    # 原有逻辑 + 新增逻辑（未隔离，可能影响原功能）
    pass

# ✅ 正确方式：新增扩展函数
def crawl_additional_data():
    # 新增功能专用逻辑（独立函数，不影响原有逻辑）
    pass

def crawl_data():
    # 保持原有逻辑不变
    pass
```

#### 迭代验证机制
```
修复1个问题 → 验证通过 → 修复下1个问题
     ↓ 验证失败
   回滚代码 → 重新分析 → 再次修复
```

**重要原则**: 
- 验证失败必须回滚，不得在错误基础上叠加修改
- 每次反馈必须明确指出差异点
- 不允许"应该没问题了"等模糊表述

### 1.3 架构合规优先原则

#### 配置驱动架构的铁律

对于采用**配置驱动架构**的项目（如ConfigDriven模式），AI必须100%遵守以下原则：

**必须遵守**:
- ✅ 所有配置项必须在配置文件中定义（如`config.yaml`、`table_config.yaml`）
- ✅ 所有操作必须通过配置管理器完成（如`ConfigDrivenTableManager`）
- ✅ 配置文件是唯一真实数据源

**严格禁止**:
- ❌ 使用独立SQL脚本绕过配置驱动架构
- ❌ 硬编码配置信息
- ❌ 任何临时补救措施违背架构原则

#### 遇到工具报错的正确处理方式

**场景**: 配置驱动工具（如ConfigDrivenTableManager）报错，无法完成操作

**❌ 错误做法**（违背架构）:
```python
# 遇到工具报错时，绕过架构直接用SQL
conn.execute("CREATE TABLE ...")
# 这会破坏配置单一数据源，导致配置文件与实际状态不一致
```

**✅ 正确做法**:
```
1. 诊断工具报错的根因（如类型错误、参数缺失）
2. 修复工具本身的bug
3. 删除所有受影响的对象（如表）
4. 重新通过配置驱动工具创建
```

**核心理念**:
> "短期痛苦（修复bug）远好于长期技术债务（临时补救）"

临时补救的后果:
- 配置文件失去单一数据源的意义
- 系统可维护性急剧下降
- 团队协作成本指数级上升
- 后续开发者无法追溯真实状态

**金标准测试**:
```
如果删除整个系统，能否仅通过配置文件100%重建？
如果答案是"否"，说明架构已被破坏。
```

#### 保护范围定义

项目应创建`PROTECTED.md`文件，列出禁止AI擅自修改的核心模块：

```
# 禁止AI自动修改的内容

## 核心业务模块
1. `/core/trade_executor.py` - 交易执行核心
2. `/core/risk_manager.py` - 风险控制核心

## 数据库相关
3. `/db/schema/` - 数据库表结构定义
4. `/db/migrations/` - 数据库迁移脚本

## 配置文件
5. `/config/risk_limits.yaml` - 风险参数
6. `/config/trading_params.yaml` - 交易参数

## 说明
以上内容修改需人工确认，AI仅可提交修改建议。
```

**AI处理规则**:
- 修改前必须检查是否涉及保护范围
- 若涉及，自动终止并提示"需人工确认"
- 仅提供修改建议和影响评估，不直接修改

### 1.4 工具驱动验证原则

#### 强制使用工具验证
**禁止仅凭代码审查判断修复成功**，必须通过以下至少一种方式验证:

1. **MCP工具验证** (推荐优先级最高)
   - chrome-devtools-mcp: 前端错误检测、网络请求验证
   - 其他适用的MCP工具

2. **自动化测试验证**
   - puppeteer: 用户交互流程测试
   - playwright: 跨浏览器/跨设备测试

3. **AI Agents辅助分析**
   - root-cause-debugger: 根因分析
   - code-reviewer: 代码质量审查
   - database-architect-cn: 数据库相关问题
   - web-fullstack-architect: 架构设计问题

#### 验证证据要求
每次修复必须提供**可追溯的证据**:
- 工具输出结果（截图或日志）
- 自动化测试通过记录
- 关键指标数据（如响应时间、错误率）

### 1.5 核心原则总结

#### 五大核心原则

**1. 最小变更原则**
- 只修改目标相关的最小代码块
- 避免"顺带优化"或"顺带重构"
- 新增功能优先用"扩展"而非"修改"
- 一次修改1-2个相关函数/文件

**2. 分层验证原则**
- 第一层：AI自验证（语法、逻辑、影响评估）
- 第二层：工具验证（MCP工具 + 自动化测试）
- 第三层：人工验证（对照成功标准逐项检查）
- 多层级验证确保修改质量

**3. 可回溯原则**
- 任何修改都必须能够快速回滚
- 提供版本标签和分支管理
- 数据库变更必须有迁移脚本（upgrade/downgrade）
- 保留修复前的代码作为备份（如`function_v1()`）

**4. 透明化原则**
- 所有修改过程必须可追踪
- 提供完整的修复说明文档
- 代码变更必须有前后对比
- 修复过程必须可审计（工具使用记录、测试结果）

**5. 架构合规原则**
- 100% 遵循项目架构设计
- 对于配置驱动架构：严禁绕过配置管理器
- 严禁任何临时补救措施违背架构原则
- 遇到工具报错，修复工具而非绕过工具
- 配置文件必须是唯一真实数据源

#### 原则优先级

当多个原则发生冲突时，遵循以下优先级：

```
架构合规原则 > 可回溯原则 > 最小变更原则 > 分层验证原则 > 透明化原则
```

**示例**：
- 如果修复工具bug需要修改较多代码（违反最小变更），但能保证架构合规，则应优先保证架构合规
- 如果某个修复无法提供完整回滚方案，则不应执行该修复

### 1.6 适用场景

本规范适用于以下场景的代码修改和BUG修复：

#### Web应用开发
- 前端交互BUG修复（JavaScript错误、UI异常）
- API接口问题处理（网络请求、数据格式）
- 样式布局调整（响应式设计、跨浏览器兼容）
- 性能优化（页面加载、资源占用）

#### 后端系统开发
- 量化交易系统代码修改
- 数据采集与处理模块
- 数据库操作优化
- 微服务架构调整

#### 跨模块功能开发
- 新功能集成
- 模块间接口调整
- 数据流重构
- 第三方服务集成

#### 系统维护与优化
- 性能瓶颈优化
- 安全漏洞修复
- 技术债务清理
- 系统架构升级

#### 不适用场景

以下场景**不适用**本规范，需要特殊处理：

- ❌ 紧急生产环境故障修复（需要更快速的流程）
- ❌ 概念验证(PoC)或原型开发（可以放宽验证要求）
- ❌ 一次性脚本或工具（不需要严格的版本控制）
- ❌ 实验性功能开发（在独立环境中进行）

**注意**：即使在不适用场景中，也应遵守**架构合规原则**和**可回溯原则**。

---

## 二、BUG修复任务规范

### 2.1 任务清单必填项

每个BUG必须包含以下信息:

| 项目 | 必填 | 说明 | 示例 |
|------|------|------|------|
| 问题ID | ✅ | 唯一标识，格式：P{优先级}-{简要描述} | P0-登录失败 |
| 现象描述 | ✅ | 具体的错误表现，包含错误信息 | 点击登录无反应，控制台报错"TypeError: Cannot read property 'token' of undefined" |
| 预期结果 | ✅ | 修复后的正确行为 | 登录成功后跳转到/dashboard，localStorage存在token |
| 代码位置 | ✅ | 文件路径和行号 | src/views/Login.vue 第45行 |
| 推荐工具 | ✅ | MCP工具/Agents/测试工具 | chrome-devtools-mcp + root-cause-debugger + puppeteer |
| 验证方式 | ✅ | 如何确认修复成功 | 提供登录成功截图 + 控制台无错误截图 + 自动化测试通过记录 |
| 成功标准 | ✅ | 可量化的检查项 | ✓ 控制台无错误 ✓ localStorage有token ✓ URL包含/dashboard |

### 2.2 工具选择指导原则

#### 按问题类型选择工具

**前端交互问题**:
- 主要工具: chrome-devtools-mcp
- 辅助Agent: root-cause-debugger
- 测试工具: puppeteer
- 验证重点: 控制台无错误、用户操作流畅

**API/网络请求问题**:
- 主要工具: chrome-devtools-mcp（Network面板）
- 辅助Agent: code-reviewer
- 测试工具: playwright
- 验证重点: 状态码正确、响应数据完整

**样式/布局问题**:
- 主要工具: chrome-devtools-mcp（Elements面板）
- 辅助Agent: web-fullstack-architect
- 测试工具: playwright（跨设备）
- 验证重点: 多设备显示正常、响应式适配

**数据库问题**:
- 主要工具: 无（依赖数据库客户端）
- 辅助Agent: database-architect-cn
- 测试工具: 数据库测试脚本
- 验证重点: 查询性能、数据一致性

**架构设计问题**:
- 主要工具: 无
- 辅助Agent: first-principles-fullstack-architect
- 测试工具: 集成测试
- 验证重点: 架构合理性、可扩展性

#### 工具组合原则

**最小工具集**: 至少使用1个MCP工具 或 1个Agent
**推荐组合**: 1个MCP工具 + 1个Agent + 1个自动化测试工具
**复杂问题**: 可使用多个工具，但需说明每个工具的作用

### 2.3 任务清单模板示例

```
【BUG修复任务清单】

## 问题ID：P0-登录失败

**现象描述**:
用户输入正确账号密码后，点击登录按钮无反应。
控制台错误: "Uncaught TypeError: Cannot read property 'token' of undefined"

**预期结果**:
点击登录按钮后，页面跳转到 /dashboard，localStorage 中保存有效的 token

**代码位置**:
src/views/Login.vue 第45行（handleLogin 函数）

**推荐工具**:
- MCP工具: chrome-devtools-mcp（控制台错误检测、网络请求验证）
- Agent: root-cause-debugger（分析错误根因）
- 测试工具: puppeteer（自动化登录流程测试）

**验证方式**:
1. chrome-devtools-mcp 验证控制台无错误
2. 提供登录成功后的页面截图
3. 提供 localStorage 存储 token 的截图
4. 提供 puppeteer 自动化测试通过的日志

**成功标准**:
- ✅ 控制台无 JavaScript 错误
- ✅ localStorage 中存在 token 字段
- ✅ 页面 URL 包含 /dashboard
- ✅ 自动化测试 3/3 通过
```

---

## 三、工具使用指导方针

### 3.1 MCP工具使用原则

#### chrome-devtools-mcp 核心能力

**必须知道的功能**:
1. **控制台监控**: 捕获 JavaScript 错误、警告、日志
2. **网络请求分析**: 检查 API 调用状态码、响应时间、数据格式
3. **性能指标获取**: 页面加载时间、资源占用情况
4. **视觉验证**: 截图保存，对比修复前后

**适用场景**:
- 前端 JavaScript 错误
- API 接口调试
- 性能问题排查
- UI 显示异常

**输出要求**:
- 错误信息必须包含完整堆栈
- 网络请求必须包含状态码和响应数据
- 截图必须清晰可见，标注关键区域

#### 其他MCP工具

根据项目实际使用的工具，遵循以下原则:
- **功能明确**: 清楚工具能做什么、不能做什么
- **输出标准化**: 统一输出格式，便于存档
- **可复现**: 同样的问题在同样环境下应得到同样结果

### 3.2 自动化测试工具指导

#### puppeteer / playwright 使用原则

**必须测试的场景**:
1. **用户核心流程**: 登录、注册、支付等关键操作
2. **异常情况处理**: 网络中断、无效输入、权限不足
3. **跨浏览器兼容性**: Chrome、Firefox、Safari（playwright）
4. **响应式设计**: 桌面、平板、手机视图

**测试脚本要求**:
- 必须包含断言验证（不能只执行操作不验证结果）
- 必须有错误处理（测试失败时截图保存）
- 必须输出清晰的测试报告（通过/失败/跳过）
- 必须可重复执行（幂等性）

**产出物标准**:
```
测试报告必须包含:
- 测试用例总数
- 通过/失败/跳过数量
- 失败用例的截图和日志
- 执行时间
- 测试覆盖率（如适用）
```

### 3.3 AI Agents 使用规范

#### root-cause-debugger

**使用时机**:
- 错误原因不明确
- 多层级调用栈分析
- 需要追溯问题源头

**输出要求**:
- 必须提供根因分析结论（不能只列现象）
- 必须提供修复建议（优先级排序）
- 必须评估修复风险（影响范围）

**分析深度标准**:
- 浅层分析: 定位到出错的函数/文件
- 中层分析: 追溯到调用链上的关键节点
- 深层分析: 找到架构或设计层面的根本原因

#### code-reviewer

**审查范围**:
- 代码规范: 命名、格式、注释
- 安全漏洞: XSS、CSRF、SQL注入
- 性能问题: 大循环、内存泄漏、重复请求
- 最佳实践: 错误处理、参数验证、日志记录

**审查报告要求**:
- 必须分级: 严重/重要/一般/建议
- 必须明确: 问题位置（文件名+行号）
- 必须可操作: 提供修复建议或示例代码

#### database-architect-cn

**分析能力**:
- 查询性能优化
- 索引设计建议
- 数据模型评估
- 事务处理优化

**输出标准**:
- 性能问题必须量化（执行时间、影响行数）
- 优化建议必须可实施（具体的SQL或配置）
- 风险必须明确（数据迁移、锁表时间）

#### web-fullstack-architect

**核心定位**: 工程实践、技术选型、前后端协作

**适用场景**:
1. **技术选型决策**
   - 前端框架选择（React/Vue/Angular）
   - 后端框架选择（Express/Koa/NestJS）
   - 数据库选型（SQL/NoSQL）
   - 状态管理方案（Redux/MobX/Pinia）

2. **工程化实践**
   - 构建工具配置（Webpack/Vite）
   - 代码规范工具（ESLint/Prettier）
   - 测试框架选择（Jest/Vitest）
   - CI/CD流程设计

3. **前后端协作**
   - API设计规范（RESTful/GraphQL）
   - 数据格式约定
   - 前后端分离架构

4. **性能优化技术**
   - 打包体积优化
   - 代码分割策略
   - 资源加载优化

**产出要求**:
- 技术选型必须有对比分析（优缺点、适用场景）
- 工程配置必须有具体示例
- 性能优化必须有预期指标

#### first-principles-fullstack-architect

**核心定位**: 第一性原理分析、系统架构设计、架构演进

**与web-fullstack-architect的区别**:
- **web-fullstack-architect**: 回答"用什么技术"、"怎么实现"（工程层面）
- **first-principles-fullstack-architect**: 回答"为什么这样设计"、"本质是什么"（原理层面）

**协同使用流程**:
```
1. first-principles: 分析业务本质 → 设计架构原则
2. web-fullstack: 基于原则 → 选择具体技术栈
3. first-principles: 验证技术方案 → 符合第一性原理
```

**适用场景**:
1. **系统架构设计**
   - 从0到1的架构设计
   - 核心业务模块划分
   - 服务边界定义

2. **第一性原理分析**
   - 业务问题的本质分析
   - 技术方案的底层逻辑验证
   - 复杂度来源识别

3. **架构演进路径**
   - 单体→分层→微服务的演进评估
   - 同步→异步的演进分析

4. **技术选型的第一性原理验证**
   - 验证web-fullstack推荐的技术是否符合业务本质
   - 识别过度设计或设计不足
   - 分析架构决策的长期影响

**产出要求**:
- 架构设计必须有图示说明
- 必须阐述业务本质和架构原则
- 技术选型验证必须说明是否符合第一性原理

### 3.4 BUG知识库与BUGer服务集成

#### 核心原则：BUGer是最终权威知识库

**强制要求**:
- ✅ 所有BUG必须提交到BUGer服务作为最终知识库
- ✅ 调试前，必须先在BUGer中搜索已有解决方案
- ✅ 发现新BUG后，必须通过AI调用token提交到BUGer
- ✅ 本地文档（`BUG知识库.md`）仅作为临时记录，最终必须同步到BUGer

#### BUG处理标准工作流

```
┌──────────────────────────────────────────┐
│ 1. 发现BUG/开始调试                        │
└──────────────────────┬───────────────────┘
                       ↓
┌──────────────────────────────────────────┐
│ 2. 在BUGer服务中搜索已有解决方案            │
│    - 使用错误码/错误信息作为关键词           │
│    - 检查相同组件/模块的历史BUG              │
└──────────────────────┬───────────────────┘
                       ↓
              ┌────────┴────────┐
              │  找到解决方案？   │
              └────────┬────────┘
         是 ←─────────┤───────────→ 否
          │           │              │
          ↓           ↓              ↓
┌─────────────┐  ┌─────────────┐  ┌──────────────────┐
│ 3a. 应用已有 │  │ 3b. 验证方案 │  │ 3c. AI分析新BUG   │
│     解决方案 │  │     是否有效 │  │     并修复        │
└──────┬──────┘  └──────┬──────┘  └────────┬─────────┘
       │                 │                   │
       ↓                 ↓                   ↓
┌─────────────────────────────────────────���───────────┐
│ 4. 通过tools/bug_reporter.py提交到BUGer              │
│    - 新BUG: 完整上下文 + 修复方案                      │
│    - 已有BUG: 补充新的解决场景或更新修复状态            │
└──────────────────────┬──────────────────────────────┘
                       ↓
┌──────────────────────────────────────────┐
│ 5. 记录到本地文档（可选）                   │
│    - BUG知识库.md（临时记录）               │
│    - 最终以BUGer为准                       │
└──────────────────────────────────────────┘
```

#### BUG Reporter客户端使用规范

**工具位置**: `tools/bug_reporter.py`

**环境配置**（在`.env`文件中设置）:
```bash
# BUGer服务配置
BUGER_API_URL=http://localhost:3003/api
BUGER_API_KEY=sk_test_xyz123
PROJECT_ID=mystocks
```

**使用方法**:

1. **单个BUG提交**:
```python
from tools.bug_reporter import BugReporter

reporter = BugReporter()

# 格式化BUG数据
bug_data = reporter.format_bug(
    error_code="IMPORT_ERROR_001",
    title="缺少require_admin函数导致后端启动失败",
    message="在app.core.security模块中缺少require_admin函数",
    severity="critical",  # critical/high/medium/low
    stack_trace="ImportError: cannot import name 'require_admin'...",
    context={
        "component": "backend",
        "module": "app.core.security",
        "file": "web/backend/app/core/security.py",
        "fix": "添加require_admin函数用于管理员权限验证",
        "status": "FIXED"
    }
)

# 提交BUG
result = reporter.report_bug(bug_data)
```

2. **批量BUG提交**:
```python
bugs = [bug1_data, bug2_data, bug3_data]
result = reporter.report_bugs_batch(bugs)
```

3. **队列收集模式**（适合高频错误）:
```python
# 收集错误（不立即提交）
reporter.collectError(error, context={"module": "api"})

# 达到批次大小或定时自动提交
# 或手动刷新
reporter.flushQueue()
```

#### BUG数据结构标准

所有提交到BUGer的BUG必须包含以下字段：

```python
{
    "errorCode": str,         # 错误代码（如"IMPORT_ERROR_001"）
    "title": str,             # 简明标题（50字符以内）
    "message": str,           # 详细描述（包含问题原因和影响）
    "severity": str,          # 严重程度：critical/high/medium/low
    "stackTrace": str,        # 完整错误堆栈（如有）
    "context": {              # 上下文信息
        "timestamp": str,     # 发现时间（ISO格式）
        "project": str,       # 项目ID（如"mystocks"）
        "project_name": str,  # 项目名称（如"MyStocks"）**必填**
        "project_root": str,  # 项目根目录（如"/opt/claude/mystocks_spec"）**必填**
        "component": str,     # 组件（frontend/backend/database）
        "module": str,        # 具体模块路径
        "file": str,          # 文件路径
        "fix": str,           # 修复方案描述
        "fix_commit": str,    # 修复提交哈希（如已提交）
        "status": str,        # 状态：OPEN/IN_PROGRESS/FIXED/CLOSED
        "session": str,       # 会话日期（YYYY-MM-DD）
        "bug_id": str         # 本地BUG编号（如BUG-NEW-003）
    }
}
```

**项目信息字段说明**:
- `project`: 项目ID,用于BUGer服务的项目分类
- `project_name`: **必填**,项目的人类可读名称,用于同名项目BUG优先查询
- `project_root`: **必填**,项目的绝对路径,便于定位文件和重现问题

#### AI的强制要求

**在修复BUG过程中，AI必须**:

1. **修复前检查（分层查询策略）**:
   - **第一层**: 使用BUGer API搜索**同名项目**下的相同错误码/错误信息
     - 查询条件: `project_name=当前项目名称 AND (errorCode=xxx OR message LIKE '%xxx%')`
     - 优先级: **最高** (100%相同的项目环境，解决方案直接适用)
   - **第二层**: 搜索**同类型组件**的相似BUG
     - 查询条件: `component=当前组件 AND errorCode=xxx`
     - 优先级: **高** (相同技术栈，解决方案大概率适用)
   - **第三层**: 搜索**相同错误代码**的所有项目BUG
     - 查询条件: `errorCode=xxx`
     - 优先级: **中** (通用解决方案，需评估适用性)
   - 如果找到已知解决方案，优先使用而非重新分析
   - 向用户汇报："该BUG在BUGer知识库中已有记录（BUG-ID: XXX，项目: YYY），建议使用已验证的解决方案"

2. **修复后提交**:
   - 新发现的BUG必须通过`tools/bug_reporter.py`提交到BUGer
   - 提交必须包含完整的context信息
   - 提交后保存响应结果到`bug_report_log.json`
   - 向用户汇报"BUG已提交到BUGer知识库（BUG-ID: XXX），供未来参考"

3. **错误处理**:
   - 如果BUGer服务不可用（Connection refused），记录到本地日志
   - 提示用户"BUGer服务当前不可用，BUG已记录到本地日志（bug_report_log.json），待服务恢复后可重新提交"
   - 不因BUGer不可用而中断BUG修复流程

#### BUGer服务API参考

**基础URL**: `http://localhost:3003/api`

**认证**: 通过`X-API-Key`请求头

**核心端点**:

1. **提交单个BUG**:
```
POST /api/bugs
Headers: X-API-Key: <api_key>
Body: { errorCode, title, message, severity, stackTrace, context }
Response: { success, statusCode, data: { bugId, status, createdAt } }
```

2. **批量提交**:
```
POST /api/bugs/batch
Headers: X-API-Key: <api_key>
Body: { bugs: [...] }
Response: { success, data: { summary: { successful, failed } } }
```

3. **搜索BUG** (AI调用):
```
GET /api/bugs?search=<keyword>&project=<project_id>
Response: { bugs: [...] }
```

#### 知识库同步原则

**本地文档 vs BUGer服务**:

| 特性 | 本地`BUG知识库.md` | BUGer服务 |
|------|-------------------|-----------|
| 定位 | 临时记录、快速查阅 | 最终权威知识库 |
| 更新频率 | 会话结束后更新 | 实时提交 |
| 搜索能力 | 手动查找 | API搜索、智能匹配 |
| 数据完整性 | 可能滞后 | 最新、最完整 |
| 使用场景 | 离线查阅、会话总结 | 在线搜索、AI查询 |

**同步规则**:
- ✅ 每次BUG修复会话结束后，必须将所有新BUG提交到BUGer
- ✅ `BUG知识库.md`中的所有历史BUG应一次性同步到BUGer
- ✅ 后续以BUGer为准，本地文档仅作为补充参考

#### 集成检查清单

在每次BUG修复会话中，AI必须确认：

- [ ] 修复前已在BUGer中搜索该BUG
- [ ] 如有已知解决方案，已评估其适用性
- [ ] 修复完成后已通过`bug_reporter.py`提交
- [ ] 提交结果已记录到`bug_report_log.json`
- [ ] 向用户汇报BUGer提交状态（成功/失败+原因）

---

## 四、AI修复输出标准

### 4.1 修复说明文档必填项

每次修复后，AI **必须** 提供包含以下内容的修复说明:

#### 1. 修复原因分析

**要求**:
- 必须说明问题的根本原因（不能只说"代码有错"）
- 必须追溯到具体的代码逻辑错误
- 必须说明为什么会导致用户观察到的现象

**示例**:
```
✅ 合格的分析:
"handleLogin 函数直接访问 res.data.token，但当认证失败时，
后端返回 {status:200, data:null}，导致访问 null.token 报错"

❌ 不合格的分析:
"代码有问题，已修复"
```

#### 2. 使用工具记录

**必须明确记录**:
- 使用了哪些MCP工具（及具体功能）
- 使用了哪些AI Agents（及分析结论）
- 使用了哪些测试工具（及测试结果）

**示例**:
```
使用工具:
- chrome-devtools-mcp
  · 功能: 获取控制台错误信息
  · 结果: 发现 TypeError at Login.vue:45
  
- root-cause-debugger
  · 功能: 分析错误根因
  · 结果: 定位到缺少 null 值检查
  
- puppeteer
  · 功能: 自动化登录流程测试
  · 结果: 3个测试用例全部通过
```

#### 3. 代码变更清单

**格式要求**:
```
文件: src/views/Login.vue
修改类型: 修复
修改位置: 第 45-55 行

修改前:
\`\`\`javascript
const token = res.data.token;
localStorage.setItem('token', token);
\`\`\`

修改后:
\`\`\`javascript
if (!res || !res.data || !res.data.token) {
  throw new Error('登录失败：响应数据格式错误');
}
const token = res.data.token;
localStorage.setItem('token', token);
\`\`\`

修改说明:
添加了响应数据的空值检查，防止访问 undefined 属性
```

**禁止行为**:
- ❌ 只贴修改后的代码，不展示修改前的代码
- ❌ 只说"修改了某某文件"，不展示具体改了什么
- ❌ 修改多个文件但只说明其中一个

#### 4. 自测证据

**必须提供的证据**:
1. **工具验证结果**
   - chrome-devtools-mcp 输出（控制台无错误）
   - 网络请求状态（API返回200）
   - 截图（关键UI状态）

2. **自动化测试结果**
   - 测试用例列表（名称+状态）
   - 通过率统计（如 3/3 通过）
   - 失败用例的错误日志（如有）

3. **性能指标**（如适用）
   - 响应时间
   - 资源占用
   - 加载速度

**证据格式示例**:
```
自测结果:

1. chrome-devtools-mcp 验证
   ✅ 控制台无错误
   ✅ 网络请求 POST /api/login 返回 200
   ✅ localStorage 成功保存 token
   
2. puppeteer 自动化测试
   ✅ 正确账号密码登录测试 - 通过
   ✅ 错误密码提示测试 - 通过
   ✅ 空用户名验证测试 - 通过
   通过率: 3/3 (100%)
   
3. 截图证据
   - 登录成功页面: test-results/login-success.png
   - localStorage 状态: test-results/storage.png
```

#### 5. 未修复问题说明

如果存在未修复的问题，**必须明确说明**:
- 问题ID
- 未修复原因（技术限制、需求不明确、超出修改范围等）
- 建议的后续处理方式

**禁止**:
- ❌ 隐瞒未修复的问题
- ❌ 声称"所有问题已修复"但实际有遗漏
- ❌ 用模糊的语言搪塞（如"基本解决"）

### 4.2 修复说明完整模板

```
【修复说明】

## 问题ID: P0-登录失败

### 修复原因分析
handleLogin 函数中未对后端响应进行数据验证。当用户输入错误密码时，
后端返回 {status: 200, data: null, message: "密码错误"}，
前端直接访问 res.data.token 导致 "Cannot read property 'token' of null" 错误。

根本原因: 缺少对后端异常响应的处理逻辑。

### 使用工具记录
1. chrome-devtools-mcp
   - 获取控制台错误堆栈
   - 检查网络请求响应数据
   - 结论: 确认 res.data 为 null 导致错误

2. root-cause-debugger
   - 分析调用链
   - 结论: 建议添加响应数据验证

3. puppeteer
   - 执行自动化登录测试
   - 结论: 修复后全部测试通过

### 代码变更清单

#### 变更1: 添加响应数据验证
- 文件: src/views/Login.vue
- 位置: 第 45-60 行
- 类型: 修复

修改前:
\`\`\`javascript
const handleLogin = async () => {
  const res = await api.login(username, password);
  const token = res.data.token;
  localStorage.setItem('token', token);
  this.$router.push('/dashboard');
};
\`\`\`

修改后:
\`\`\`javascript
const handleLogin = async () => {
  try {
    const res = await api.login(username, password);
    
    // 验证响应数据
    if (!res || !res.data || !res.data.token) {
      const errorMsg = res?.message || '登录失败：响应数据格式错误';
      throw new Error(errorMsg);
    }
    
    const token = res.data.token;
    localStorage.setItem('token', token);
    this.$router.push('/dashboard');
    
  } catch (error) {
    console.error('登录失败:', error);
    this.$message.error(error.message);
  }
};
\`\`\`

变更说明:
- 添加了 try-catch 错误处理
- 添加了响应数据的空值检查
- 优化了错误提示信息（显示后端返回的具体错误）

### 自测证据

#### 1. chrome-devtools-mcp 验证
- ✅ 控制台无 JavaScript 错误
- ✅ 网络请求 POST /api/login 返回状态码 200
- ✅ localStorage 成功保存 token (key: 'token', value: 'eyJhbGc...')

#### 2. puppeteer 自动化测试
测试用例执行结果:
- ✅ 正确账号密码登录 - 通过 (1.2s)
- ✅ 错误密码提示 - 通过 (0.8s)
- ✅ 空用户名验证 - 通过 (0.5s)
- ✅ 网络异常处理 - 通过 (1.0s)

通过率: 4/4 (100%)
测试日志: test-results/login-test-report.log

#### 3. 截图证据
- 登录成功页面: test-results/login-success.png
- localStorage 状态: test-results/localStorage.png
- 错误提示展示: test-results/error-message.png

### 潜在风险评估
无。本次修改仅在原有函数内添加验证逻辑，不影响其他模块。

### 未修复问题说明
无。所有在任务清单中的问题均已修复并通过验证。
```

---

## 五、验证与闭环机制

### 5.1 三层验证体系

#### 第一层: AI自验证（必须）

AI 提交修复代码前，**必须自行检查**:

**检查项**:
- [ ] 语法检查: 代码是否符合语言规范
- [ ] 逻辑检查: 修改是否解决了描述的问题
- [ ] 影响评估: 是否可能影响其他功能
- [ ] 边界条件: 是否考虑了异常情况
- [ ] 性能影响: 是否引入性能问题

**输出格式**:
```
=== AI 自验证报告 ===

语法检查: ✅ 通过 (无语法错误)
逻辑检查: ✅ 通过 (已添加数据验证逻辑)
影响评估: ✅ 通过 (仅修改 Login.vue，无跨模块影响)
边界条件: ✅ 通过 (已处理 null、undefined、网络异常)
性能影响: ✅ 通过 (仅增加 3 行验证代码，性能影响可忽略)

建议: 可进入人工验证阶段
```

#### 第二层: 工具验证（必须）

**MCP工具验证**:
- 必须使用至少1个MCP工具验证修复效果
- 必须提供工具输出截图或日志
- 必须对比修复前后的差异

**自动化测试验证**:
- 必须编写或运行相关测试用例
- 必须提供测试通过率
- 失败的测试必须说明原因

**验证失败处理**:
- 如果验证失败，必须回滚代码
- 必须重新分析问题
- 不得在错误代码基础上继续修改

#### 第三层: 人工验证（必须）

**用户必须做的事**:
1. 根据"验证方式"逐项测试
2. 对照"成功标准"检查是否达标
3. 记录实际结果 vs 预期结果

**验证不通过时的处理**:
```
针对问题 ID: P0-登录失败

验证结果: ❌ 未通过

实际结果:
- 登录后控制台仍有错误: "Cannot read property 'name' of undefined"
- URL 未跳转到 /dashboard，停留在 /login

预期结果:
- 控制台无错误
- URL 包含 /dashboard

差异分析:
AI 只修复了 token 的空值检查，但未修复用户信息 (res.data.user.name) 的空值检查

要求:
请重新修复，确保对所有响应数据进行完整验证
```

### 5.2 闭环反馈流程

```
提交修复 → 工具验证 → 人工验证
              ↓ 失败        ↓ 失败
           回滚代码      记录差异
              ↓             ↓
           重新分析 ← 精准提需
              ↓
           再次修复 → ... (循环)
              
              ↓ 通过        ↓ 通过
           标记完成 → 进入下一问题
```

**原则**:
- 验证失败必须回滚，不得在错误基础上叠加修改
- 每次反馈必须明确指出差异点
- 同一问题连续3次修复失败，需升级处理（人工介入或更换方案）

### 5.3 验证标准量化

**控制台验证**:
- ✅ 合格: 0 errors, 0 warnings（或仅有不相关的warning）
- ❌ 不合格: 存在任何与修复相关的error或warning

**网络请求验证**:
- ✅ 合格: 状态码 200-299，响应时间 < 500ms
- ❌ 不合格: 状态码 4xx/5xx，或响应时间过长

**UI显示验证**:
- ✅ 合格: 截图与设计稿一致，无溢出/错位/闪烁
- ❌ 不合格: 存在任何视觉异常

**自动化测试验证**:
- ✅ 合格: 通过率 100%，或失败用例与本次修复无关
- ❌ 不合格: 存在因本次修复导致的测试失败

---

## 六、效率与成本控制

### 6.1 Token优化原则

#### 模型选择策略

**使用轻量模型的场景**:
- 单文件小范围修改（≤50行代码）
- 简单的语法错误修复
- 已明确问题根因的快速修复

**必须使用高级模型的场景**:
- 多文件关联分析（≥3个文件）
- 复杂的根因追溯
- 架构设计决策
- 连续2次修复失败后的重新分析

**禁止行为**:
- ❌ 为了省Token使用不合适的模型（导致修复失败反而浪费更多Token）
- ❌ 重复提交相同的问题描述（应缓存分析结果）

#### 测试用例模板化

**原则**: 使用测试模板减少重复描述

**示例**:
```
登录测试模板:
- 场景1: 正确凭据 → 期望成功登录
- 场景2: 错误密码 → 期望提示错误
- 场景3: 空用户名 → 期望提示必填
```

复用模板时，只需填充具体参数，而不是每次都写完整的测试描述。

#### 批量操作优化

**原则**: 一次工具调用获取多项数据

**推荐做法**:
```
一次性获取:
- 控制台错误列表
- 网络请求记录
- 性能指标数据
- 页面截图
```

**禁止做法**:
```
多次单独调用:
- 调用1: 获取控制台错误
- 调用2: 获取网络请求
- 调用3: 获取性能指标
- 调用4: 截图
```

### 6.2 测试效率提升

#### 并行测试

**原则**: 独立的测试用例应并行执行

**示例**:
```
可并行执行:
- 登录功能测试
- 注册功能测试
- 找回密码功能测试

不可并行执行:
- 注册 → 登录 → 修改资料 (有依赖关系)
```

#### 智能测试选择

**原则**: 仅测试受影响的模块

**示例**:
```
修改了 Login.vue → 仅执行登录相关测试
修改了全局状态管理 → 执行全量回归测试
```

#### 测试结果缓存

**原则**: 代码未变化时，可复用之前的测试结果

**条件**:
- 代码hash值相同
- 测试环境相同
- 缓存时间 < 5分钟

### 6.3 成本监控

#### Token使用记录

**要求**: 每次AI调用必须记录Token消耗

**记录内容**:
- 任务ID
- 使用的模型
- Token数量
- 成功/失败状态

#### 效率评估

**定期评估**（每周/每月）:
- 平均每个BUG的Token消耗
- 修复成功率
- 平均修复轮次

**优化目标**:
- Token消耗降低 30-50%
- 一次修复成功率 > 90%
- 平均修复轮次 < 1.5

---

## 七、禁止性规定

### 7.1 绝对禁止的表述

**AI 不得出现以下表述**:

❌ "所有BUG已修复"
❌ "可以安全使用了"
❌ "应该没问题了"
❌ "基本解决了"
❌ "已经修复完成"

**必须使用的表述**:

✅ "已完成以下修复，待验证: ..."
✅ "已修复问题ID: P0-xxx, P1-xxx，请验证"
✅ "自测通过，等待人工验证确认"

### 7.2 禁止的修改行为

**未经允许不得修改**:
- ❌ 任务清单外的代码
- ❌ 核心业务逻辑（如交易、支付、权限）
- ❌ 数据库表结构（除非明确要求）
- ❌ 第三方库版本（可能引入兼容性问题）

**禁止的"优化"行为**:
- ❌ 修复BUG时"顺便重构"无关代码
- ❌ 未经要求添加新功能
- ❌ 修改代码风格（除非是代码规范问题）

### 7.3 禁止省略的内容

**修复说明中不得省略**:
- ❌ 修复原因（不能只说"已修复"）
- ❌ 代码变更前后对比（不能只给修改后的代码）
- ❌ 自测结果（不能只说"测试通过"）
- ❌ 使用的工具（不能只说"已验证"）

### 7.4 禁止绕过的流程

**不得跳过的环节**:
- ❌ 工具验证（不能仅凭代码审查）
- ❌ 自动化测试（不能仅凭手动测试）
- ❌ 证据提交（不能仅口头说明）
- ❌ 失败回滚（不能在错误基础上继续改）

---

## 八、质量保障体系

### 8.1 代码质量标准

#### 必须遵守的规范

**错误处理**:
- 所有异步操作必须有 try-catch
- 所有外部数据必须验证（API响应、用户输入）
- 错误信息必须对用户友好

**参数验证**:
- 函数参数必须类型检查
- 必填参数必须验证非空
- 数值参数必须验证范围

**日志记录**:
- 关键操作必须记录日志
- 错误必须记录堆栈
- 敏感信息必须脱敏

#### 代码审查要点

**安全性**:
- [ ] 无 XSS 漏洞（用户输入必须转义）
- [ ] 无 CSRF 漏洞（关键操作必须验证token）
- [ ] 无 SQL 注入（使用参数化查询）
- [ ] 敏感信息不得硬编码

**性能**:
- [ ] 无大循环（> 1000次）
- [ ] 无内存泄漏（事件监听必须解绑）
- [ ] 无重复请求（相同数据应缓存）
- [ ] 资源必须按需加载

**可维护性**:
- [ ] 命名清晰（变量名、函数名见名知义）
- [ ] 注释完整（复杂逻辑必须注释）
- [ ] 函数职责单一（不超过50行）
- [ ] 魔法数字必须定义为常量

### 8.2 测试质量标准

#### 测试覆盖率目标

**核心功能**: 
- 单元测试: ≥ 90%
- 集成测试: ≥ 80%
- E2E测试: ≥ 70%

**一般功能**:
- 单元测试: ≥ 80%
- 集成测试: ≥ 70%
- E2E测试: ≥ 60%

#### 测试用例质量

**必须测试的场景**:
- 正常流程（Happy Path）
- 异常情况（错误输入、网络失败）
- 边界条件（空值、最大值、最小值）
- 并发场景（多用户、同时操作）

**测试用例命名规范**:
```
格式: test_{功能}_{场景}_{预期结果}

示例:
- test_login_withCorrectCredentials_shouldSucceed
- test_login_withWrongPassword_shouldShowError
- test_login_withEmptyUsername_shouldShowWarning
```

### 8.3 数据库操作质量保障

#### ORM类型安全原则

**问题背景**: Python/SQLAlchemy的隐式类型推断不总是可靠，特别是在批量插入、JSONB字段、默认值等场景。

**显式类型转换要求**:

❌ **错误做法** (依赖隐式推断):
```python
default_value=col_def.get('default')  # 可能被推断为NUMERIC而非VARCHAR
```

✅ **正确做法** (显式转换):
```python
default_val = col_def.get('default')
if default_val is not None:
    default_val = str(default_val)  # 显式转换为字符串
```

**需要显式类型转换的场景**:
1. JSONB字段
2. 默认值处理
3. 可选字段的None值
4. 批量插入操作

#### PostgreSQL特定要求

**ENUM类型必须指定name**:

❌ 错误:
```python
Column(SQLEnum('CREATE', 'ALTER', 'DROP'), nullable=False)
# PostgreSQL报错: ENUM type requires a name
```

✅ 正确:
```python
Column(SQLEnum('CREATE', 'ALTER', 'DROP', name='operation_type_enum'), nullable=False)
```

**原因**: PostgreSQL的ENUM是用户自定义类型(UDT)，必须有名称；MySQL的ENUM是字段级约束。

### 8.4 版本控制与回滚保障

#### 分支管理策略

**分支结构**:
```
main (生产) → develop (开发) → feature/功能 (功能分支)
                        → hotfix/修复 (紧急修复)
```

**规则**:
- main分支: AI不得直接修改，仅通过PR合并
- 功能分支: 基于main创建，命名清晰
- 合并条件: 自动化测试通过 + 人工审核

#### 版本标签规范

```bash
# 格式: v{版本号}_{类型}_{简述}
v2.1.0_feature_data_clean   # 功能版本
v2.1.1_fix_missing_value    # 修复版本
v2.1.2_hotfix_critical      # 紧急修复
```

#### 回滚方案

**代码回滚**:
```bash
git reset --hard v2.1.0_feature_data_clean
```

**数据库回滚** (如适用):
- 必须提供迁移脚本 (upgrade/downgrade)
- 支持向前和向后兼容

### 8.5 错误案例库与知识沉淀

#### 错误案例记录格式

```
## 案例 #002: 配置驱动工具绕过错误

**时间**: 2025-10-24
**问题**: 配置驱动工具报错，试图用SQL绕过
**根因**: PostgreSQL ENUM缺少name、类型转换错误
**正确做法**: 修复工具bug，重新通过配置工具创建
**关键学习**: 
- 修复工具而非绕过工具
- 架构合规=100%，不允蠆99%
**预防**: ENUM必须name、显式类型转换
```

#### AI自检清单

修改前必须检查:
- [ ] 是否绕过了配置管理器？
- [ ] 是否使用显式类型转换？
- [ ] PostgreSQL ENUM是否有name？
- [ ] 是否检查了PROTECTED.md？
- [ ] 是否参考了历史错误案例？

### 8.6 性能质量标准

#### 性能指标要求

**页面加载**:
- 优秀: < 1秒
- 良好: < 2秒
- 可接受: < 3秒
- 需优化: ≥ 3秒

**API响应**:
- 优秀: < 100ms
- 良好: < 300ms
- 可接受: < 500ms
- 需优化: ≥ 500ms

**首屏渲染**:
- 优秀: < 0.5秒
- 良好: < 1秒
- 可接受: < 1.5秒
- 需优化: ≥ 1.5秒

#### 性能优化原则

**必须优化的场景**:
- 页面加载时间 > 3秒
- API响应时间 > 500ms
- 内存占用增长 > 50MB/分钟
- CPU占用 > 80%

**优化优先级**:
1. 影响用户体验的性能问题（页面卡顿、操作无响应）
2. 影响系统稳定性的问题（内存泄漏、死循环）
3. 资源浪费问题（重复请求、冗余计算）

### 8.4 文档质量标准

#### 必须更新的文档

**代码修改后必须更新**:
- 接口文档（API变更）
- 架构文档（架构调整）
- 部署文档（依赖变更）
- 用户手册（功能变更）

#### 文档完整性检查

**技术文档必须包含**:
- [ ] 背景说明（为什么要做）
- [ ] 解决方案（怎么做的）
- [ ] 使用说明（如何使用）
- [ ] 注意事项（潜在风险）
- [ ] 测试验证（如何验证）

---

## 九、附录

### 9.1 快速检查清单

#### BUG修复前

- [ ] 问题描述清晰明确
- [ ] 优先级已标注
- [ ] 相关代码位置已定位
- [ ] 推荐工具已选择
- [ ] 验证方式已明确
- [ ] 成功标准已量化

#### 修复过程中

- [ ] 仅修改相关代码
- [ ] 使用工具分析了根因
- [ ] 代码有前后对比
- [ ] 考虑了边界情况
- [ ] 添加了错误处理
- [ ] 遵循了代码规范

#### 修复完成后

- [ ] 通过了工具验证
- [ ] 通过了自动化测试
- [ ] 提供了测试证据
- [ ] 进行了回归测试
- [ ] 更新了相关文档
- [ ] 记录了修复过程

### 9.2 常见问题判断

**如何判断是否需要使用Agent?**

| 问题特征 | 推荐Agent | 原因 |
|---------|----------|------|
| 错误原因不明 | root-cause-debugger | 需要深层分析 |
| 代码质量问题 | code-reviewer | 需要规范审查 |
| 数据库性能差 | database-architect-cn | 需要专业优化 |
| 技术选型疑问 | web-fullstack-architect | 需要工程实践指导 |
| 架构设计疑问 | first-principles-fullstack-architect | 需要第一性原理分析 |

**如何判断修复是否成功?**

| 验证项 | 判断标准 | 工具 |
|--------|---------|------|
| 控制台无错误 | 0 errors | chrome-devtools-mcp |
| API调用正常 | 状态码 200-299 | chrome-devtools-mcp |
| 自动化测试通过 | 通过率 100% | puppeteer/playwright |
| 性能符合预期 | < 性能标准 | chrome-devtools-mcp |

### 9.3 术语解释

**MCP工具**: Model Context Protocol工具，用于浏览器自动化和调试

**AI Agents**: 专业化的AI辅助工具，针对特定领域提供深度分析

**根因分析**: 追溯问题的根本原因，而非表面现象

**回归测试**: 验证修复没有破坏原有功能的测试

**幂等性**: 多次执行产生相同结果的特性

---

## 十、总结

### 核心原则回顾

1. **证据驱动**: 一切以工具验证结果和测试数据为准
2. **小步迭代**: 每次只修复少量问题，快速验证反馈
3. **透明可追溯**: 所有修复过程必须有完整记录
4. **质量优先**: 宁可多花时间验证，不可匆忙上线

### 成功标准

**修复被认为成功的充要条件**:
- 工具验证通过（chrome-devtools-mcp 等）
- 自动化测试通过（puppeteer/playwright）
- 人工验证通过（对照成功标准逐项检查）
- 提供了完整的修复说明和证据

### 禁止性原则

**绝对不允许**:
- 声称"已修复"但未提供验证证据
- 修改任务清单外的无关代码
- 在验证失败后继续叠加修改
- 省略修复说明中的必填项

---

**文档版本**: v4.0 纲领版  
**适用场景**: Web端程序BUG修复、AI协作开发  
**核心价值**: 建立可验证、可追溯、可控制的BUG修复流程
